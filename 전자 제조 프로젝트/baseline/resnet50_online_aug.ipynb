{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import argparse\n",
    "from cv2 import imread, normalize, resize\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import logging\n",
    "import sys\n",
    "from PIL import Image\n",
    "\n",
    "from utils import euclidean_metric, one_hot, count_acc\n",
    "from utils import pprint, set_gpu, ensure_path, AverageMeter, Timer, accuracy, one_hot\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision.models as models\n",
    "from torch import nn, optim, autograd\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "from random import sample, random\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, ConcatDataset, Dataset, TensorDataset, WeightedRandomSampler\n",
    "import os.path as osp\n",
    "from tqdm import tqdm\n",
    "\n",
    "from random import sample, random\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "batch_size = 32\n",
    "num_epoch = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Customdataset(data.Dataset):\n",
    "    def __init__(self,transform = None):\n",
    "        dalist=None\n",
    "        self.file_paths = []\n",
    "        self.label = []\n",
    "        self.transform = transform\n",
    "\n",
    "        file_path = '/home/iai/Desktop/SH/cognex/d-sub-15pin_for-seoultech/imageset/single_image.2class.subject-split.trainval-repeat0/fold.5-5/ratio/100%/train.1-1.txt' # 폴더 경로\n",
    "\n",
    "        with open(file_path) as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        image_names = [line.rstrip('\\n') for line in lines]\n",
    "        \n",
    "                \n",
    "        with open('/home/iai/Desktop/SH/cognex/d-sub-15pin_for-seoultech/annotation/single_image.6class.json', 'r') as json_file:\n",
    "            data = json.load(json_file)\n",
    "            \n",
    "        path_image = \"/home/iai/Desktop/SH/cognex/d-sub-15pin_for-seoultech/image/\"\n",
    "        files = os.listdir(path_image)\n",
    "        \n",
    "        for file in files:\n",
    "            if file in image_names:\n",
    "                self.label.append(data['single_image'][file]['class'][0])\n",
    "                self.file_paths.append(path_image + '/' + file)\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.file_paths)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        label = self.label[idx]\n",
    "        idx_num = idx\n",
    "        tmp_prob = np.random.rand()\n",
    "        weight_dict = {\"0\" :  (400/250) / (400/250 + 400 * 5 / 30), \"1\" : (400/30) / (400/250 + 400 * 5 / 30), \"2\" : (400/30) / (400/250 + 400 * 5 / 30), \n",
    "                       \"3\" : (400/30) / (400/250 + 400 * 5 / 30), \"4\" : (400/30) / (400/250 + 400 * 5 / 30), \"5\" : (400/30) / (400/250 + 400 * 5 / 30)}        \n",
    "        \n",
    "        if weight_dict[str(label)] < tmp_prob:\n",
    "            while True : \n",
    "                idx_num = np.random.randint(len(self.file_paths))\n",
    "                tmp_prob =  np.random.rand()\n",
    "                label = self.label[idx_num]\n",
    "                \n",
    "                if weight_dict[str(label)] > tmp_prob:\n",
    "                    break\n",
    "\n",
    "        path = self.file_paths[idx_num]\n",
    "        image = Image.open(path).convert('RGB')\n",
    "        \n",
    "          \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, int(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImgAugTransform:\n",
    "  def __init__(self):\n",
    "    self.aug = iaa.Sequential([\n",
    "                iaa.BlendAlpha((0, 0.25),\n",
    "                iaa.Affine(rotate=(-25, 25))),\n",
    "                iaa.GaussianBlur(sigma=(0, 2)),\n",
    "                ])\n",
    "      \n",
    "  def __call__(self, img):\n",
    "    img = np.array(img).T\n",
    "    img = self.custom_lightness(img, 8 * np.random.randn())\n",
    "    img = self.aug.augment_image(img)\n",
    "    return img.T\n",
    "\n",
    "  def custom_lightness(self, image, custom_sigma):\n",
    "    img = image\n",
    "    img_YUV = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)    \n",
    "    y = img_YUV[:,:,0]    \n",
    "    \n",
    "    rows = y.shape[0]    \n",
    "    cols = y.shape[1]\n",
    "    \n",
    "    ### illumination elements와 reflectance elements를 분리하기 위해 log를 취함\n",
    "    imgLog = np.log1p(np.array(y, dtype='float') / 255) # y값을 0~1사이로 조정한 뒤 log(x+1)\n",
    "    \n",
    "    ### frequency를 이미지로 나타내면 4분면에 대칭적으로 나타나므로 \n",
    "    ### 4분면 중 하나에 이미지를 대응시키기 위해 row와 column을 2배씩 늘려줌\n",
    "    M = 2*rows + 1\n",
    "    N = 2*cols + 1\n",
    "    \n",
    "    ### gaussian mask 생성 sigma = 10\n",
    "    sigma = custom_sigma\n",
    "    (X, Y) = np.meshgrid(np.linspace(0, N-1, N), np.linspace(0, M-1, M)) # 0~N-1(and M-1) 까지 1단위로 space를 만듬\n",
    "    Xc = np.ceil(N/2) # 올림 연산\n",
    "    Yc = np.ceil(M/2)\n",
    "    gaussianNumerator = (X - Xc)**2 + (Y - Yc)**2 # 가우시안 분자 생성\n",
    "    \n",
    "    ### low pass filter와 high pass filter 생성\n",
    "    LPF = np.exp(-gaussianNumerator / (2*sigma*sigma))\n",
    "    HPF = 1 - LPF\n",
    "    \n",
    "    ### LPF랑 HPF를 0이 가운데로 오도록iFFT함. \n",
    "    ### 사실 이 부분이 잘 이해가 안 가는데 plt로 이미지를 띄워보니 shuffling을 수행한 효과가 났음\n",
    "    ### 에너지를 각 귀퉁이로 모아 줌\n",
    "    LPF_shift = np.fft.ifftshift(LPF.copy())\n",
    "    HPF_shift = np.fft.ifftshift(HPF.copy())\n",
    "    \n",
    "    ### Log를 씌운 이미지를 FFT해서 LPF와 HPF를 곱해 LF성분과 HF성분을 나눔\n",
    "    img_FFT = np.fft.fft2(imgLog.copy(), (M, N))\n",
    "    img_LF = np.real(np.fft.ifft2(img_FFT.copy() * LPF_shift, (M, N))) # low frequency 성분\n",
    "    img_HF = np.real(np.fft.ifft2(img_FFT.copy() * HPF_shift, (M, N))) # high frequency 성분\n",
    "    \n",
    "    ### 각 LF, HF 성분에 scaling factor를 곱해주어 조명값과 반사값을 조절함\n",
    "    gamma1 = 0.3\n",
    "    gamma2 = 1.5\n",
    "    img_adjusting = gamma1*img_LF[0:rows, 0:cols] + gamma2*img_HF[0:rows, 0:cols]\n",
    "    \n",
    "    ### 조정된 데이터를 이제 exp 연산을 통해 이미지로 만들어줌\n",
    "    img_exp = np.expm1(img_adjusting) # exp(x) + 1\n",
    "    img_exp = (img_exp - np.min(img_exp)) / (np.max(img_exp) - np.min(img_exp)) # 0~1사이로 정규화\n",
    "    img_out = np.array(255*img_exp, dtype = 'uint8') # 255를 곱해서 intensity값을 만들어줌\n",
    "    \n",
    "    ### 마지막으로 YUV에서 Y space를 filtering된 이미지로 교체해주고 RGB space로 converting\n",
    "    img_YUV[:,:,0] = img_out\n",
    "    result = cv2.cvtColor(img_YUV, cv2.COLOR_YUV2BGR)\n",
    "    \n",
    "    return result\n",
    "\n",
    "aug_transforms = ImgAugTransform()\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "              \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225]),\n",
    "        aug_transforms\n",
    "        \n",
    "        ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##커스텀 데이터셋\n",
    "dataset = Customdataset(transform=data_transforms)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "print(f\"train size :{train_size}\")\n",
    "val_size = len(dataset) - train_size\n",
    "print(f\"test_size :{val_size}\")\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print(f\"train_dataset :{len(train_dataset)}\")\n",
    "print(f'test dataset :{len(val_dataset)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsampler import ImbalancedDatasetSampler\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                               batch_size = batch_size, #배치사이즈\n",
    "                                               shuffle = True\n",
    "                                               )\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset,\n",
    "                                               batch_size = batch_size,                                              \n",
    "                                               shuffle = True\n",
    "                                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import torch\n",
    "\n",
    "resnet50_pretrained = models.resnet50(pretrained=True)\n",
    "\n",
    "num_classes = 6\n",
    "num_ftrs = resnet50_pretrained.fc.in_features\n",
    "resnet50_pretrained.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "resnet50_pretrained.to(device)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorchtools import EarlyStopping # 위 링크의 깃허브 파일에서 임포트\n",
    "\n",
    "early_stopping = EarlyStopping(patience = 3, verbose = True, min_epoch=30)\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(resnet50_pretrained.parameters(), lr=0.00005)\n",
    "\n",
    "train_loss_arr =[]\n",
    "val_loss_arr =[]\n",
    "n = len(train_loader)\n",
    "\n",
    "model_path = '/home/iai/Desktop/SH/cognex/model/'\n",
    "\n",
    "for i in range(num_epoch):\n",
    "    \n",
    "    train_running_loss = 0.0\n",
    "    for j,[image,label] in enumerate(train_loader):\n",
    "        x = image.to(device)\n",
    "        y =  label.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = resnet50_pretrained.forward(x)\n",
    "        \n",
    "        loss = loss_func(output,y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_running_loss += loss.item()\n",
    "    \n",
    "    train_loss_arr.append(train_running_loss / n)\n",
    "        \n",
    "    resnet50_pretrained.eval()\n",
    "    val_running_loss = 0.0\n",
    "    for j,[image,label] in enumerate(val_loader):\n",
    "        \n",
    "        x = image.to(device)\n",
    "        y =  label.to(device)\n",
    "        \n",
    "        y_pred = resnet50_pretrained(x)\n",
    "        loss = loss_func(y_pred, y)\n",
    "\n",
    "        val_running_loss += loss.item()\n",
    "    \n",
    "    val_loss_arr.append(val_running_loss / len(val_loader))       \n",
    "    early_stopping(val_running_loss, resnet50_pretrained)\n",
    "    torch.save(resnet50_pretrained, model_path + str(i) + 'epoch_model.pt')\n",
    "    \n",
    "    print('[%d] train_loss: %.5f , val_loss: %.5f ' %(i + 1, train_running_loss / len(train_loader) , val_running_loss / len(val_loader)))\n",
    "        \n",
    "    if early_stopping.early_stop and i > 20: # 조건 만족 시 조기 종료\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.plot(train_loss_arr,\n",
    "         color='skyblue',\n",
    "         marker='o', markerfacecolor='blue',\n",
    "         markersize=4)\n",
    "\n",
    "plt.plot(val_loss_arr,\n",
    "         color='pink',\n",
    "         marker='x', markerfacecolor='red',\n",
    "         markersize=4)\n",
    "\n",
    "plt.title('Model loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Customdataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,transform = None):\n",
    "        dalist=None\n",
    "        self.file_paths = []\n",
    "        self.label = []\n",
    "        self.context = []\n",
    "        self.transform = transform\n",
    "\n",
    "        file_path = '/home/iai/Desktop/SH/cognex/d-sub-15pin_for-seoultech/imageset/single_image.2class.subject-split.trainval-repeat0/fold.5-5/ratio/100%/test.1.txt' # 폴더 경로\n",
    "\n",
    "        with open(file_path) as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        image_names = [line.rstrip('\\n') for line in lines]\n",
    "\n",
    "\n",
    "        path = '/home/iai/Desktop/SH/cognex/d-sub-15pin_for-seoultech/image' # 폴더 경로\n",
    "        files = os.listdir(path) # 해당 폴더에 있는 파일 이름을 리스트 형태로 받음\n",
    "        \n",
    "        with open('/home/iai/Desktop/SH/cognex/d-sub-15pin_for-seoultech/annotation/single_image.6class.json', 'r') as json_file:\n",
    "            data = json.load(json_file)  \n",
    "    \n",
    "        for file in files:\n",
    "            if file in image_names:\n",
    "                self.label.append(data['single_image'][file]['class'][0])\n",
    "                self.file_paths.append(path + '/' + file)\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.file_paths)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.file_paths[idx]\n",
    "        image = Image.open(path).convert('RGB')\n",
    "        label = self.label[idx]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, int(label)\n",
    "    \n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "        \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225]),\n",
    "\n",
    "        ])\n",
    "\n",
    "    \n",
    "test_dataset = Customdataset(transform=data_transforms)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                               batch_size = 32                                       \n",
    "                                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_pretrained = models.resnet50(pretrained=True)\n",
    "\n",
    "num_classes = 6\n",
    "num_ftrs = resnet50_pretrained.fc.in_features\n",
    "resnet50_pretrained.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "resnet50_pretrained.to(device)\n",
    "\n",
    "best_model_epoch = val_loss_arr.index(min(val_loss_arr))\n",
    "resnet50_pretrained = torch.load(model_path + str(best_model_epoch) +'epoch_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "pred_ls = []\n",
    "real_ls = []\n",
    "\n",
    "context_ls = [] \n",
    "\n",
    "with torch.no_grad(): # 파라미터 업데이트 같은거 안하기 때문에 no_grad를 사용.\n",
    "  # net.eval() # batch normalization이나 dropout을 사용하지 않았기 때문에 사용하지 않음. 항상 주의해야함.\n",
    "  for data in test_loader:\n",
    "    images, labels = data[0].to(device), data[1].to(device) \n",
    "    outputs = resnet50_pretrained(images)\n",
    "    _, predicted = torch.max(outputs.data, 1) # 6개의 class중 가장 값이 높은 것을 예측 label로 추출.\n",
    "    total += labels.size(0) # test 개수\n",
    "    correct += (predicted == labels).sum().item() # 예측값과 실제값이 맞으면 1 아니면 0으로 합산.\n",
    "    \n",
    "    pred_ls.append(predicted.cpu().numpy())\n",
    "    real_ls.append(labels.cpu().numpy())\n",
    "    \n",
    "    #context_ls.append(context)\n",
    "\n",
    "print(f'accuracy of 1600 test images: {100*correct/total}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.array(pred_ls).reshape(-1)\n",
    "real = np.array(real_ls).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(pred, real))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(con_mat, labels, title='Confusion Matrix', cmap=plt.cm.get_cmap('Blues'), normalize=False):\n",
    "    plt.imshow(con_mat, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    marks = np.arange(len(labels))\n",
    "    nlabels = []\n",
    "    for k in range(len(con_mat)):\n",
    "        n = sum(con_mat[k])\n",
    "        nlabel = '{0}(n={1})'.format(labels[k],n)\n",
    "        nlabels.append(nlabel)\n",
    "    plt.xticks(marks, labels)\n",
    "    plt.yticks(marks, nlabels)\n",
    "\n",
    "    thresh = con_mat.max() / 2.\n",
    "    if normalize:\n",
    "        for i, j in itertools.product(range(con_mat.shape[0]), range(con_mat.shape[1])):\n",
    "            plt.text(j, i, '{0}%'.format(con_mat[i, j] * 100 / n), horizontalalignment=\"center\", color=\"white\" if con_mat[i, j] > thresh else \"black\")\n",
    "    else:\n",
    "        for i, j in itertools.product(range(con_mat.shape[0]), range(con_mat.shape[1])):\n",
    "            plt.text(j, i, con_mat[i, j], horizontalalignment=\"center\", color=\"white\" if con_mat[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "    \n",
    "cm_df = confusion_matrix(pred, real)    \n",
    "label=['ok', 'scratch', 'fm', 'pin', 'dent', 'glue']\n",
    "plot_confusion_matrix(cm_df, labels=label, normalize=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sh_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7ca6ade228fb881d3061bf3bfd2d80b29326ddee5d719b0d4da242b8e3e15ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
